{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e2ca309",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2aa0af",
   "metadata": {},
   "source": [
    "Stemming is a natural language processing (NLP) technique used to reduce words to their root or base form, which is called the \"stem.\" Stemming is commonly used as a pre-processing step in text mining and information retrieval tasks, such as document classification, clustering, and search engines.\n",
    "\n",
    "The stem is the part of the word that remains after removing any prefixes or suffixes. For example, the word \"running\" can be reduced to its stem \"run\" by removing the suffix \"-ing\". Similarly, the word \"cats\" can be reduced to its stem \"cat\" by removing the suffix \"-s\".\n",
    "\n",
    "Stemming algorithms use a set of rules or algorithms to perform this process automatically, based on linguistic principles and heuristics. There are several popular stemming algorithms, such as Porter Stemming Algorithm, Snowball Stemming Algorithm, and Lancaster Stemming Algorithm.\n",
    "\n",
    "The primary goal of stemming is to reduce the number of unique words in a corpus, while still preserving the core meaning of the text. This can improve the efficiency and accuracy of many NLP tasks, by reducing the number of distinct tokens that must be processed or analyzed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "691313f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "walking -> walk\n",
      "jumps -> jump\n",
      "jumped -> jump\n",
      "jumping -> jump\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Create a stemmer object\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Stem some example words\n",
    "words = [\"walking\", \"jumps\", \"jumped\", \"jumping\"]\n",
    "for word in words:\n",
    "    stemmed_word = stemmer.stem(word)\n",
    "    print(f\"{word} -> {stemmed_word}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b306cca",
   "metadata": {},
   "source": [
    "### lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b620996",
   "metadata": {},
   "source": [
    "In Natural Language Processing (NLP), stemming and lemmatization are two commonly used techniques for reducing words to their base form. While both techniques aim to reduce the inflectional and derivational forms of words, they differ in their approach and the results they produce.\n",
    "\n",
    "Stemming is a process of reducing words to their base or root form by removing the suffixes from words. For example, the stemming algorithm might convert the words \"running\", \"runners\", and \"run\" to the base word \"run\". This technique is useful in cases where the context of the words is not important, such as in search engines, where stemming can help to retrieve documents that contain the root form of a word.\n",
    "\n",
    "Lemmatization, on the other hand, is a more sophisticated approach that involves identifying the morphological root of a word based on its context in a sentence. This technique takes into account the part of speech of a word and applies different normalization rules to different parts of speech. For example, the lemma of the word \"am\" is \"be\", while the lemma of the word \"running\" is \"run\".\n",
    "\n",
    "In Python, there are several libraries that implement these techniques. The most popular libraries for stemming are Porter Stemmer and Snowball Stemmer, while the most popular library for lemmatization is WordNet Lemmatizer. Here's an example of how to use the Porter Stemmer and WordNet Lemmatizer in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "641cd84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'quick', 'brown', 'fox', 'jump', 'over', 'the', 'lazi', 'dog']\n",
      "['The', 'quick', 'brown', 'fox', 'jumped', 'over', 'the', 'lazy', 'dog']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "text = \"The quick brown foxes jumped over the lazy dogs\"\n",
    "\n",
    "# Stemming\n",
    "stemmer = PorterStemmer()\n",
    "stemmed_words = [stemmer.stem(word) for word in word_tokenize(text)]\n",
    "print(stemmed_words)\n",
    "\n",
    "# Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in word_tokenize(text)]\n",
    "print(lemmatized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bda9c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
